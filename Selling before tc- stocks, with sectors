import vectorbt as vbt
import yfinance as yf
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from scipy.optimize import least_squares
from sklearn.metrics import r2_score
import warnings
from lppls import lppls
import time
from vectorbt.portfolio.enums import SizeType
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from vectorbt.generic.plotting import Scatter
import os

warnings.filterwarnings('ignore')

url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
tables = pd.read_html(url, header=0)  # Reads all tables on the page. header=0 uses the first row as column names.
# Let's assume that the first table on the page is the one you want
table = tables[0]
# Now, you can select the columns 'Symbol' and 'GICS Sector'
stocks_with_sectors = table[['Symbol', 'GICS Sector']]
stocks_with_sectors = stocks_with_sectors[~stocks_with_sectors['Symbol'].isin(['BRK.B', 'BF.B', 'GEHC', 'CEG', 'OTIS', 'CARR', 'OGN'])]

# Keep the sector data for later use
sectors = {row['Symbol']: row['GICS Sector'] for _, row in stocks_with_sectors.iterrows()}

stocks = stocks_with_sectors['Symbol'].tolist()
stocks100 = stocks[:100]
stocks10 = stocks[:10]

# Parameters
model_window_param = 70
b_weight_param = 0.75
r2_weight_param = 0.25
signal_threshold_param = 65
buy_back_param = 30
max_searches_param = 20
days_after_tc_param = 30

# Date range
start_date='2022-01-01'
end_date='2023-01-01'

#Helper functions
def loss(params, x, y):
    return func(x, *params) - y

def func(x, a, b, c):
    return a * np.exp(b * x) + c

start_time = time.time()

def load_quarterly_revenue(symbol, start_date):
    # Load the revenue data from the CSV file
    filename = f"{symbol}_quarterly_income_statement.csv"

    # Check if the file exists
    if not os.path.isfile(filename):
        print(f"File '{filename}' does not exist. Skipping {symbol}.")
        return None, None

    revenue_df = pd.read_csv(f"{symbol}_quarterly_income_statement.csv")

    # Convert the 'fiscalDateEnding' column to datetime
    revenue_df['fiscalDateEnding'] = pd.to_datetime(revenue_df['fiscalDateEnding'])

    # Set the index to the 'fiscalDateEnding' column
    revenue_df.set_index('fiscalDateEnding', inplace=True)

    # Sort the DataFrame by the index (i.e., 'fiscalDateEnding')
    revenue_df.sort_index(inplace=True)

    # Extract the 'totalRevenue' column
    revenue = revenue_df['totalRevenue']

    # Select the revenue data for the last quarter before start date
    last_revenue_before_start = revenue[revenue.index < start_date].last('Q').iloc[-1]

    # Select the revenue data for the same quarter in the previous year
    same_quarter_previous_year = revenue.asof(start_date - pd.DateOffset(years=1))

    if same_quarter_previous_year is None:
        raise ValueError(f"Not enough historical data for {symbol} to perform analysis starting from {start_date}")

    return last_revenue_before_start, same_quarter_previous_year

def compute_fetch_start_date(start_date, model_window):
    start_date_dt = pd.to_datetime(start_date)
    business_days = 0
    current_date = start_date_dt
    while business_days < model_window:
        current_date -= pd.DateOffset(days=1)
        if current_date.dayofweek < 5:  # It's a weekday
            business_days += 1
    return current_date.strftime("%Y-%m-%d")

fetch_start_date = compute_fetch_start_date(start_date, model_window_param)

# Downloading data
data = yf.download(stocks10, start=fetch_start_date, end=end_date)['Close']
data = data.ffill().bfill()

print(data.columns)

# This is the actual indicator. Currently, it is based on the modelling of the log of 5-day moving average of the price data
# model_window days before the current date to an exponential curve. This modelling happens every 30 days (but can be modified).
# This is slightly arbitrary, but is just a starting point I chose, where the threshold depends on the multiple of the
# model's exponent and its r^2 value, ie how closely it resembles a faster-than-exponential growth. If the model meets the
# requirements, we fit it to the LPPL model. I have tried doing the normal curve_fit in this case, but that takes an 
# incredibly long time. However, there is an lppl library in Python which is very efficient and, having visualised it, 
# seems to be quite good at fitting. There is a parameter, max_searches, which can be adjusted to prevent overfitting etc.
# Then, if the predicted bubble burst is more than 14 days into the future, we buy the stock, and sell it 14 days before tc.
# We sell everything at the end of the window.
def analyze_stocks(data, model_window = model_window_param):
    df_b = pd.DataFrame()
    df_r2 = pd.DataFrame()
    all_dates = data.index.unique()
    for i in range(model_window, len(all_dates), 30): # here we loop over dates first
        date_b_values = []
        date_r2_values = []
        tickers = []
        for ticker in data.columns:
            df = data[ticker]
            if all_dates[i] not in df.index:
                continue
            historical_data = df.loc[all_dates[i-model_window]:all_dates[i]]
            historical_data = historical_data.rolling(window=5).mean().dropna()
            if len(historical_data) == 0:
                continue
            xdata = (historical_data.index - historical_data.index[0]).days.values
            ydata = historical_data.values
            log_ydata = np.log(ydata + 1).ravel()
            res = least_squares(loss, x0=(1, 0.01, 1), args=(xdata, log_ydata))
            fitted_y = func(xdata, *res.x).ravel()
            a, b, c = res.x
            r2 = r2_score(log_ydata, fitted_y)

            last_revenue_before_start, same_quarter_previous_year = load_quarterly_revenue(ticker, df.index[i])
            # Calculate inverse of percentage change in revenue
            revenue_change = (last_revenue_before_start - same_quarter_previous_year) / same_quarter_previous_year
            revenue_adjustment = 1 / (1 + revenue_change)
            # Adjust b and r2 values based on revenue growth
            b = b * revenue_adjustment

            date_b_values.append(b)
            date_r2_values.append(r2)
            tickers.append(ticker)
        scaler = StandardScaler()
        date_b_values_scaled = scaler.fit_transform(np.array(date_b_values).reshape(-1,1)).ravel()
        date_r2_values_scaled = scaler.fit_transform(np.array(date_r2_values).reshape(-1,1)).ravel()
        df_b_temp = pd.DataFrame(date_b_values_scaled, columns=[all_dates[i]], index=tickers).T
        df_r2_temp = pd.DataFrame(date_r2_values_scaled, columns=[all_dates[i]], index=tickers).T
        df_b = pd.concat([df_b, df_b_temp], axis=0)
        df_r2 = pd.concat([df_r2, df_r2_temp], axis=0)
    return df_b, df_r2

sector_data = {
    sector: data[[symbol for symbol in stocks_with_sectors[stocks_with_sectors['GICS Sector'] == sector]['Symbol'].tolist() if symbol in data.columns]]
    for sector in stocks_with_sectors['GICS Sector'].unique()
}

sector_data = {k: v for k, v in sector_data.items() if not v.empty}

# Creating dataframes for b and r2 values for each sector
sector_b_values = {}
sector_r2_values = {}
for sector in sector_data:
    df_b_values, df_r2_values = analyze_stocks(sector_data[sector], model_window_param)
    df_b_values = df_b_values.loc[~df_b_values.index.duplicated(keep='first')]
    df_r2_values = df_r2_values.loc[~df_r2_values.index.duplicated(keep='first')]
    df_b_values = df_b_values.reindex(data.index)
    df_r2_values = df_r2_values.reindex(data.index)
    
    sector_b_values[sector] = df_b_values
    sector_r2_values[sector] = df_r2_values

initial_capital = 1000000

def exp_growth_and_r2(close,
                    df_b_values,
                    df_r2_values,
                    model_window=model_window_param,
                    signal_threshold=signal_threshold_param,
                    b_weight = b_weight_param,
                    r2_weight = r2_weight_param,
                    buy_back=buy_back_param,
                    max_searches=max_searches_param,
                    days_after_tc=days_after_tc_param):

    try:
        output = np.zeros(len(close))
        ticker = close.columns[0]
        for i in range(model_window, len(close), 30):

            if np.isnan(df_b_values.loc[close.index[i], ticker]) or np.isnan(df_r2_values.loc[close.index[i], ticker]):
                continue

            b_value = df_b_values.loc[close.index[i], ticker]
            r2_value = df_r2_values.loc[close.index[i], ticker]
            b_norm_value = 50 + (50 / 3) * b_value
            r2_norm_value = 50 + (50 / 3) * r2_value
            signal = b_norm_value * b_weight + r2_norm_value * r2_weight

            if signal > signal_threshold and close.iloc[i, 0] > close.iloc[i - model_window, 0]:
                historical_data = close.iloc[i-model_window:i]  # slice close price data for historical data
                time = [pd.Timestamp.toordinal(t) for t in historical_data.index]
                price = np.log(historical_data.values).ravel()
                observations = np.array([time, price])
                tcs = []
                for _ in range(7):
                    lppls_model = lppls.LPPLS(observations=observations)
                    tc, m, w, a, b, c1, c2, phi, O, D = lppls_model.fit(max_searches)
                    tcs.append(tc)
                tc = np.median(tcs)
                tc = tc - datetime.toordinal(historical_data.index[-1])

                if tc < buy_back:  # Sell the stock when a crash is predicted within 30 days
                    output[i] = -1
                    if (i + buy_back + days_after_tc) < len(output):  # Buy it back after 30 days
                        output[i + buy_back + days_after_tc] = 1

        output[-1] = -1  # Sell everything at the end of the window
        return output

    except Exception as e:
        print(f"Couldn't process stock. Error: {str(e)}")

# Creating the indicator
BuyIndicator = vbt.IndicatorFactory(
    input_names=['close', 'df_b_values', 'df_r2_values'],
    param_names=['model_window',
                'signal_threshold',
                'b_weight',
                'r2_weight',
                'days_after_tc',
                'max_searches',
                'buy_back'],
    output_names=['buy_indicator']
).from_apply_func(exp_growth_and_r2,
                model_window=model_window_param,
                signal_threshold=signal_threshold_param,
                b_weight = b_weight_param,
                r2_weight = r2_weight_param,
                buy_back=buy_back_param,
                max_searches=max_searches_param,
                days_after_tc=days_after_tc_param,
                keep_pd=True,
                per_column=True)

# Running the data through our indicator- days when we buy will have a value of 1, and when we sell -1. 0 otherwise
sector_buy_indicator = {}
for sector in sector_data:
    buy_indicator = BuyIndicator.run(sector_data[sector],
                                     sector_b_values[sector],
                                     sector_r2_values[sector],
                                     model_window=model_window_param,
                                     signal_threshold=signal_threshold_param,
                                     b_weight = b_weight_param,
                                     r2_weight = r2_weight_param,
                                     buy_back=buy_back_param,
                                     max_searches=max_searches_param,
                                     days_after_tc=days_after_tc_param)
    sector_buy_indicator[sector] = buy_indicator

# Getting the entry_signal and exit_signal series for each sector
sector_entry_signal = {}
sector_exit_signal = {}
for sector in sector_buy_indicator:
    entry_signal = sector_buy_indicator[sector].buy_indicator == 1
    exit_signal = sector_buy_indicator[sector].buy_indicator == -1
    
    # Dropping some extra columns to make it match data
    entry_signal.columns = entry_signal.columns.droplevel(['custom_model_window', 'custom_signal_threshold', 'custom_b_weight', 'custom_r2_weight', 'custom_buy_back', 'custom_max_searches', 'custom_days_after_tc'])
    sector_entry_signal[sector] = entry_signal
    sector_exit_signal[sector] = exit_signal

# Creating the portfolio for each sector
sector_portfolio = {}
for sector in sector_data:
    sector_portfolio[sector] = vbt.Portfolio.from_signals(
        sector_data[sector],
        sector_entry_signal[sector],
        sector_exit_signal[sector],
        init_cash=initial_capital,
        fees=0.001
    )

# Printing portfolio stats for each sector
for sector in sector_portfolio:
    print(f"Statistics for {sector} sector:")
    print(sector_portfolio[sector].stats(metrics = ["start", 
                                                    "end", 
                                                    "period", 
                                                    "start_value", 
                                                    "end_value", 
                                                    "total_return", 
                                                    "benchmark_return",
                                                    "max_gross_exposure", 
                                                    "total_fees_paid", 
                                                    "max_dd", 
                                                    "total_trades", 
                                                    "win_rate", 
                                                    "profit_factor", 
                                                    "expectancy"]))
    print(f"\nStats for {sector}:")
    print(sector_stats[sector])
    print(f"Sharpe ratio: {sector_portfolio[sector].sharpe_ratio(group_by = True, freq='D')}")
    print(f"Sortino ratio: {sector_portfolio[sector].sortino_ratio(group_by = True, freq='D')}")

#Downloading S&P 500 data
sector_portfolios = {}

# Create a portfolio for each sector
for sector in sector_data.keys():
    
    # Fetch the price data for the stocks in the current sector
    sector_df = sector_data[sector]
    
    # Create a portfolio where we simply hold the stocks in the current sector
    sector_portfolios[sector] = vbt.Portfolio.from_holding(sector_df, init_cash=initial_capital, fees=0.001)

# Create a dictionary to hold the stats for each sector
sector_stats = {}

# For each sector
for sector, portfolio in sector_portfolios.items():
    
    # Compute the portfolio stats
    sector_stats[sector] = portfolio.stats()
    
    # Print the stats for the current sector
    print(f"\nStats for {sector}:")
    print(sector_stats[sector])
    print(f"Sharpe ratio: {portfolio.sharpe_ratio(group_by = True, freq='D')}")
    print(f"Sortino ratio: {portfolio.sortino_ratio(group_by = True, freq='D')}")
end_time = time.time()
print(f'Time taken: {end_time - start_time} seconds')
